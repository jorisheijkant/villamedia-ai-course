AI kan een journalist ‘superpowers’ geven, maar moet dat ook?

Journalistieke innovatie Op het perscongres International Journalism Festival in Perugia was AI het gesprek van de dag. „Dit gaat niet over banen die verdwijnen, het gaat over banen die verbeterd worden.”

Dit artikel is geschreven door een mens. Maar als het geschreven zou zijn door een computer, gebruikmakend van de laatste AI-technologie, zou u, lezer, dat willen weten? Vermoedelijk wel. En als de computer alleen vier suggesties had gedaan voor de kop boven dit artikel, en een levende NRC-redacteur er vervolgens één had gekozen, zou dat dan in het artikel vermeld moeten worden?

Deze en vele andere vragen over kunstmatige intelligentie en journalistiek kwamen de afgelopen dagen aan bod op het International Journalism Festival in Perugia, het grootste journalistieke congres van Europa waar jaarlijks duizenden journalisten op afkomen om te luisteren naar honderden praatjes over het vak. Er waren sessies over klimaatjournalistiek, over verslag doen in Oekraïne, over een jong publiek bereiken op TikTok. Maar bij de sessies over AI stonden de langste rijen en ook onder de aanwezige journalisten, die elkaar troffen op de zonnige terrasjes, was kunstmatige intelligentie het gesprek van de dag. Hoe gaat AI de journalistiek beïnvloeden? Wat zijn de gevaren en kansen?

Kunstmatige intelligentie wordt al langer gebruikt door nieuwsorganisaties. Als een journalist googlet komt daar AI aan te pas, en als een journalist sociale media gebruikt om een artikel te verspreiden ook. Dat er de laatste tijd zoveel aandacht is voor AI komt door de razendsnelle ontwikkelingen op het gebied van generatieve AI, het soort AI dat nieuwe teksten, beelden of ander materiaal kan maken op basis van data waarmee het is getraind. Een artikel herschrijven in de stijl van Shakespeare, een foto aanpassen op basis van een paar simpele aanwijzingen.
Ombudsman NRC: Door AI spreekt het ineens niet meer voor zich dat de krant mensenwerk is
Een hele goede stagiair

Wat geldt voor talloze andere sectoren, geldt ook voor de pers: de mogelijkheden van (generatieve) AI zijn duizelingwekkend. AI kan vertalen, interviews transcriberen, teksten samenvatten, data analyseren, nieuwsbrieven schrijven, reacties van lezers onder artikelen modereren, video’s bewerken, foto’s aanpassen, illustraties creëren, teksten in een andere stijl herschrijven, en zelfs een complete nieuwssite vullen met automatisch gegenereerde artikelen.

Geen wonder dat een van de meeste gestelde vragen uit het publiek luidde: „Gaat AI mijn baan vervangen?” Want óf nieuwsorganisaties AI moeten gaan gebruiken was eigenlijk niet meer de vraag op de podia van Perugia, de vraag was: hoe? De aanwezige journalisten en uitgevers zien AI vooral als nuttig gereedschap, dat net als elk ander gereedschap ten goede en ten kwade kan worden toegepast.

Maar gaat het nu journalistieke banen vervangen? Op die vraag klonken op het podium telkens geruststellende woorden. „Dit gaat niet over banen die verdwijnen, het gaat over banen die verbeterd worden”, zei Gina Chua, uitvoerend hoofdredacteur van Semafor. Journalisten van de Amerikaanse journalistieke startup gebruiken AI al voor het controleren van artikelen: typefouten herstellen, grammatica verbeteren, namen controleren op spelling. Persbureau AP heeft „duizenden manuren” bespaard door AI in te zetten voor het transcriberen van interviews, vertelde directeur Partnerships Lisa Gibbs naast haar op het podium.

„Je kan AI zien als een hele goede stagiair”, zegt Freek Staps, ANP-hoofdredacteur en oud-NRC-journalist. „Die komt heel enthousiast binnen op de redactie, kan een hoop, maar loopt ook het risico fouten te maken.” En, voegt hij toe, „hij of zij heeft de potentie ooit beter te worden dan jij”.
Mens-machine-mens

De fouten waar Staps op doelt zijn de zogenoemde ‘hallucinaties’ waar AI-chatbots als ChatGPT inmiddels berucht om zijn. Dergelijk taalmodellen berekenen de kans dat een woord op een ander woord volgt, op basis van een ingevoerde opdracht en data waarmee ze zijn getraind. Zo kan de chatbot allerlei taal gaan uitslaan die grammaticaal wel klopt, maar vol feitelijke fouten zit. Daarnaast wijzen critici erop dat vooroordelen en misinformatie in de trainingsdata gereproduceerd kan worden door de AI.

Beducht op dergelijke fouten committeert persbureau ANP zich aan het principe ‘mens-machine-mens’. „Het schrijven van een nieuwsbericht moet beginnen met een journalistieke vraag van een mens, daarna kan je de machine inzetten om je daarbij te helpen, maar daarop volgt altijd controle door een journalist”, aldus Staps.

Hij schreef als een van de eerste hoofdredacteuren in Nederland een AI-richtlijn voor zijn journalisten. Naast het principe mens-machine-mens staat daarin dat wie een chatbot een (deel van een) ANP-artikel wil laten schrijven daar altijd toestemming voor moet vragen aan de hoofdredactie. Staps acht het op dit moment nog niet waarschijnlijk dat hij die toestemming zal geven, omdat de kans op fouten te groot is als je een chatbot vraagt grote stukken tekst te schrijven.

„ANP-journalisten gebruiken AI wél om geïnspireerd te worden. Toen een eindredacteur en auteur een kortere kop wilden maken, maar er zelf even niet uitkwamen, vroegen ze een chatbot om raad. Die kwam met een suggestie die feitelijk correct was en de lading goed dekte. Ze hebben de kop van de chatbot gekozen.”

Moeten lezers erop worden gewezen dat de computer heeft geholpen om die kop korter te maken? „Nee, dat niet. Net zomin dat de lezer moet weten dat Google is gebruikt om iets op te zoeken voor een artikel. Vooral ook niet omdat er een veiligheidscheck achter zit: de journalist beslist en niet de computer.”
Superpowers

NRC inventariseert momenteel wat de kansen en risico’s van AI-toepassingen zijn, laat adjunct-hoofdredacteur Melle Garschagen weten. „De NRC-code, waarin onze kernwaarden staan, biedt wel structuur: weet wat en wie je bronnen zijn, leg je werkwijze uit, pleeg wederhoor, check je feiten, zorg dat jouw werk eigen en uniek is. Dat verandert niet.”

In Perugia was regelmatig te horen dat AI journalisten „superpowers” kan geven. Een assistent die repetitieve klusjes kan uitvoeren, een superstagiair die in een paar seconden patronen in grote datasets kan vinden. Maar dat AI het werk van journalisten efficiënter kan maken wil nog niet zeggen dat dat móet gebeuren, zegt Nicholas Diakopoulos, universitair hoofddocent aan de Amerikaanse Northwestern University. Hij kwam naar Perugia om te vertellen over zijn onderzoek naar AI-toepassingen voor journalisten. „Efficiëntie kan betekenen dat journalisten meer artikelen kunnen schrijven, meer mensen op een dag kunnen interviewen. Dat is voor aandeelhouders misschien interessant, maar het kan het werk van een journalist ook intensiever, zwaarder maken. Je kan ook vragen: hoe kan dit gereedschap de kwaliteit van de journalistiek verbeteren? Je kan een chatbot vragen suggesties te doen een artikel op een andere manier in te steken, of meer gevarieerde stemmen erin op te nemen. Zo kan AI journalisten nieuwe perspectieven aanreiken.”

Diakopoulos vindt dat nieuwsorganisaties hun eigen AI-modellen moeten gaan ontwikkelen. „Achter Chatbots als ChatGPT en Bing zitten grote techbedrijven die niet per se geïnteresseerd zijn in het bevorderen van kwaliteitsjournalistiek. Als nieuwsorganisaties enige mate van onafhankelijkheid van Big Tech willen behouden, moeten ze serieus gaan nadenken over het ontwikkelen van eigen technologiën waarbij nieuwswaarden en publieke waarden in het ontwerp zijn opgenomen. Critici wijzen erop dat bedrijven als OpenAi van ChatGPT niet openbaar maken welke data zijn gebruikt bij het trainen van hun taalmodellen. Daardoor kunnen we minder goed achterhalen hoe deze modellen werken en waarom ze sommige uitkomsten geven. Kwaliteitsmedia zouden dat anders kunnen aanpakken, omdat ze waarden als transparantie en betrouwbaarheid onderschrijven.” 